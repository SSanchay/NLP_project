{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bad57f7-8ef7-42bd-8e23-e684ae9eece8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Простая модель с ручной обработкой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d402c6-e107-4fab-9e99-2257ea7e9180",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_ML(review: str):\n",
    "    \"функция обрабатывает текст и предсказывает на ML-модели\"\n",
    "    \n",
    "    clean_tokenized_review = tokenize(review)\n",
    "    tfid_representation = tfid.transform([clean_tokenized_review]) # ревью состоит из векторов, сверху загружаем vectorizer\n",
    "    \n",
    "    pred_proba = model_ml.predict_proba(tfid_representation)\n",
    "    \n",
    "    return pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6192a76c-4e4e-4a37-b165-d86dfe422a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# всё, что нужно для модели\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Возможно нужны будут\n",
    "# nltk.download('omw-1.4')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "# Кэшируем стоп-слова\n",
    "sw = stopwords.words('english')\n",
    "\n",
    "#Загружаем vectorizer\n",
    "tfid = load('tfidf.joblib')\n",
    "\n",
    "#Загружаем модель для sentiment_ML\n",
    "model_ml = load('logreg.joblib')\n",
    "\n",
    "def clean(text):\n",
    "    \"Функция чистит текст\"\n",
    "    text = text.lower() #нижний регистр\n",
    "    text = re.sub('<.*?>', '', text) # Remove HTML from text\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation)) # удаляем знаки препинания\n",
    "    text = re.sub(r'\\d+', ' ', text) # удаляем числа\n",
    "    \n",
    "    return text\n",
    "\n",
    "def tokenize_review(review: str):\n",
    "    \"Функция чистит текст и возвращает токенизированные слова\"\n",
    "    cleaned_review = clean(review) # cleaning text\n",
    "    wn_lemmatizer = WordNetLemmatizer() #lemmatization\n",
    "    reg_tokenizer = RegexpTokenizer('\\w+') #tokenization\n",
    "    \n",
    "    lemmatized_review = ' '.join([wn_lemmatizer.lemmatize(word, tag[0].lower())\\ # лемматизация с учётом части речи\n",
    "                                if tag[0].lower() in ['a','n','v']\\ # word - проверка на adv, noun и verb\n",
    "                                else wn_lemmatizer.lemmatize(word)\\ # простая лемматизация\n",
    "                                for word, tag in nltk.pos_tag(cleaned_review.split())]) # pos_tag - определяет часть речи\n",
    "    \n",
    "    tokenized_review = reg_tokenizer.tokenize_sents([lemmatized_review]) # ревью состоит из токенов\n",
    "    clean_tokenized_review = ' '.join([word for word in tokenized_review[0] if word not in sw]) # удаляем стоп-слова, сверху объявили sw \n",
    "    \n",
    "    return clean_tokenized_review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329b7bd3-b842-4cb4-aa43-0f481422211a",
   "metadata": {},
   "source": [
    "## Хорошая модель с ручной обработкой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61536746-eae4-4ddc-bf88-948e1eea0257",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_RNN(review: str):\n",
    "    \"функция обрабатывает текст и предсказывает на RNN-модели\"\n",
    "    \n",
    "    clean_tokenized_review = tokenize_review(review)\n",
    "    \n",
    "    num_review = [] # здесь будут вместо слов числа из словаря vocab_to_int #векторизуем\n",
    "    for word in clean_tokenized_review.split(): \n",
    "        try:\n",
    "            num_review.append(vocab_to_int[word]) \n",
    "        except KeyError as e:\n",
    "            print(f'Word {word} not in dictionary!')\n",
    "            \n",
    "    #padding \n",
    "    padding_review = num_review[-200:] #обрубаем если больше 200 слов\n",
    "    if len(num_review) <= 200:\n",
    "        padding_review = list(np.zeros(200 - len(r))) + num_review #дополняем нулями если меньше 200 слов\n",
    "        \n",
    "    tensor_review = torch.Tensor(pading_review).long().unsqueeze(0) #создаем тензор ревью для модели\n",
    "    test_h = model_rnn.init_hidden(1) #создаем hidden_state\n",
    "\n",
    "    pred = model_rnn(tensor_review, test_h) \n",
    "    pred_proba = pred[0].item()\n",
    "    \n",
    "    return pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152e9b6e-05cb-4c8e-8052-536d8a55956e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# всё что нужно для модели\n",
    "\n",
    "\n",
    "#загружаем словарь слов с\n",
    "with open('dict.json', 'r') as fp:\n",
    "    vocab_to_int = json.load(fp)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a41bef0-7ac2-4ef1-af9d-3afd15c6e564",
   "metadata": {},
   "source": [
    "## Простая модель с обработкой от BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f303a43f-69ad-491b-aa15-48ade2c69bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_BERT_ML(review: str):\n",
    "    \"функция обрабатывает текст с помощью BERT и предсказывает на ML-модели\"\n",
    "    \n",
    "    \n",
    "    return answer_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3accfa25-d426-4cba-82ca-6347ed0a4ee5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10f219e-f1aa-443a-b6e7-d72862704ef6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
