{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bad57f7-8ef7-42bd-8e23-e684ae9eece8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Простая модель с ручной обработкой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6192a76c-4e4e-4a37-b165-d86dfe422a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# всё, что нужно для модели\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from joblib import load\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "\n",
    "# Возможно нужны будут\n",
    "# nltk.download('omw-1.4')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "# Кэшируем стоп-слова\n",
    "sw = stopwords.words('english')\n",
    "\n",
    "#Загружаем vectorizer\n",
    "tfid = load('tfidf.joblib')\n",
    "\n",
    "#Загружаем модель для sentiment_ML\n",
    "model_ml = load('logreg.joblib')\n",
    "\n",
    "def clean(text):\n",
    "    \"Функция чистит текст\"\n",
    "    text = text.lower() #нижний регистр\n",
    "    text = re.sub('<.*?>', '', text) # Remove HTML from text\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation)) # удаляем знаки препинания\n",
    "    text = re.sub(r'\\d+', ' ', text) # удаляем числа\n",
    "    \n",
    "    return text\n",
    "\n",
    "def tokenize_review(review: str):\n",
    "    \"Функция чистит текст и возвращает токенизированные слова\"\n",
    "    cleaned_review = clean(review) # cleaning text\n",
    "    wn_lemmatizer = WordNetLemmatizer() #lemmatization\n",
    "    reg_tokenizer = RegexpTokenizer('\\w+') #tokenization\n",
    "    \n",
    "    lemmatized_review = ' '.join([wn_lemmatizer.lemmatize(word, tag[0].lower()) # лемматизация с учётом части речи\n",
    "                                if tag[0].lower() in ['a','n','v'] # word - проверка на adv, noun и verb\n",
    "                                else wn_lemmatizer.lemmatize(word) # простая лемматизация\n",
    "                                for word, tag in nltk.pos_tag(cleaned_review.split())]) # pos_tag - определяет часть речи\n",
    "    \n",
    "    tokenized_review = reg_tokenizer.tokenize_sents([lemmatized_review]) # ревью состоит из токенов\n",
    "    clean_tokenized_review = ' '.join([word for word in tokenized_review[0] if word not in sw]) # удаляем стоп-слова, сверху объявили sw \n",
    "    \n",
    "    return clean_tokenized_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e6d402c6-e107-4fab-9e99-2257ea7e9180",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_ML(review: str):\n",
    "    \"функция обрабатывает текст и предсказывает на ML-модели\"\n",
    "    \n",
    "    clean_tokenized_review = tokenize_review(review)\n",
    "    tfid_representation = tfid.transform([clean_tokenized_review]) # ревью состоит из векторов, сверху загружаем vectorizer\n",
    "\n",
    "    pred_proba = model_ml.predict_proba(tfid_representation) # хранит список предсказаний для двух классов \n",
    "\n",
    "    return np.round(pred_proba[0][1], 3) # берем первое и единственное предсказание и вероятность 1 класса (позитивный)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "465b6258-0ad6-4cc9-88db-58a6d88868a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.062"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#выдаёт вероятность 1 класса (позитивный)\n",
    "sentiment_ML('interesting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e954e74a-fc95-454a-bfb0-08fd630367a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_ML('great movie but')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329b7bd3-b842-4cb4-aa43-0f481422211a",
   "metadata": {},
   "source": [
    "## Хорошая модель с ручной обработкой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "61536746-eae4-4ddc-bf88-948e1eea0257",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_RNN(review: str):\n",
    "    \"функция обрабатывает текст и предсказывает на RNN-модели\"\n",
    "    \n",
    "    clean_tokenized_review = tokenize_review(review)\n",
    "    \n",
    "    num_review = [] # здесь будут вместо слов числа из словаря vocab_to_int #векторизуем\n",
    "    for word in clean_tokenized_review.split(): \n",
    "        try:\n",
    "            num_review.append(vocab_to_int[word]) \n",
    "        except KeyError as e:\n",
    "            print(f'Word {word} not in dictionary!')\n",
    "            \n",
    "    #padding \n",
    "    padding_review = num_review[-200:] #обрубаем если больше 200 слов\n",
    "    if len(num_review) <= 200:\n",
    "        padding_review = list(np.zeros(200 - len(num_review))) + num_review #дополняем нулями если меньше 200 слов\n",
    "        \n",
    "    tensor_review = torch.Tensor(padding_review).long().unsqueeze(0) #создаем тензор ревью для модели\n",
    "    test_h = model_rnn.init_hidden(1) #создаем hidden_state\n",
    "\n",
    "    pred = model_rnn(tensor_review, test_h) \n",
    "    pred_proba = pred[0].item()\n",
    "    \n",
    "    return np.round(pred_proba, 3) # выдает вероятность 1 класса (позитивный)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "1e79316b-3638-4386-9fc7-321f1d60eea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.801"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_RNN('interesting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "97f91df4-79df-4e36-9316-61313b57287e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.988"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_RNN('great movie but')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "152e9b6e-05cb-4c8e-8052-536d8a55956e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentimentGRU(\n",
       "  (embedding): Embedding(201151, 32)\n",
       "  (gru): GRU(32, 16, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (fc): Linear(in_features=16, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# всё что нужно для модели\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from json import load\n",
    "\n",
    "#загружаем словарь слово-число\n",
    "\n",
    "with open('dict.json', 'r') as fp:\n",
    "    vocab_to_int = load(fp)\n",
    "\n",
    "#загружаем модель для sentiment_RNN\n",
    "vocab_size = len(vocab_to_int) + 1 # размер словаря vocab_to_int\n",
    "output_size = 1 # задача бинарной классификации\n",
    "embedding_dim = 32 # размер слова\n",
    "hidden_dim = 16 # размер вектора истории\n",
    "n_layers = 2 # количество GRU слоев\n",
    "\n",
    "model_rnn = sentimentGRU(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
    "model_rnn.load_state_dict(torch.load('params_gru.pt', map_location=torch.device('cpu')))\n",
    "model_rnn.eval()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0125a374-4659-4c82-9158-0eb0420641dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class sentimentGRU(nn.Module):\n",
    "    def __init__(self, \n",
    "                 vocab_size, # объём словаря слов\n",
    "                 output_size, # нейроны полносвязного слоя\n",
    "                 embedding_dim, # размер выходного эмбеддинга\n",
    "                 hidden_dim, # размерность внутреннего слоя LSTM\n",
    "                 n_layers, # число слоев в LSTM\n",
    "                 drop_prob=0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.output_size = output_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        self.gru = nn.GRU(embedding_dim,\n",
    "                           hidden_dim,\n",
    "                           n_layers,\n",
    "                           dropout = drop_prob,\n",
    "                           batch_first = True)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        \n",
    "        batch_size = x.size(0)\n",
    "        embeds = self.embedding(x)\n",
    "        \n",
    "        gru_out, hidden = self.gru(embeds, hidden)\n",
    "        \n",
    "        gru_out = gru_out.contiguous().view(-1, self.hidden_dim)\n",
    "        \n",
    "        out = self.dropout(gru_out)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        sig_out = self.sigmoid(out)\n",
    "        \n",
    "        sig_out = sig_out.view(batch_size, -1)\n",
    "        \n",
    "        sig_out = sig_out[:, -1]\n",
    "        \n",
    "        return sig_out, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        \"Hidden state инициализируем нулями\"\n",
    "        \n",
    "        h0 = torch.zeros((self.n_layers), batch_size, self.hidden_dim)\n",
    "\n",
    "        hidden = h0\n",
    "        \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a41bef0-7ac2-4ef1-af9d-3afd15c6e564",
   "metadata": {},
   "source": [
    "## Простая модель с обработкой от BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f303a43f-69ad-491b-aa15-48ade2c69bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_BERT_ML(review: str):\n",
    "    \"функция обрабатывает текст с помощью BERT и предсказывает на ML-модели\"\n",
    "    \n",
    "    \n",
    "    return answer_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3accfa25-d426-4cba-82ca-6347ed0a4ee5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10f219e-f1aa-443a-b6e7-d72862704ef6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
